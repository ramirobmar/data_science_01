{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4fc38b3b-f51a-4fde-add8-ccda28357144",
    "_uuid": "00b8832b3c051b1b4ea6e8c568c57c96fd66494f",
    "collapsed": true
   },
   "source": [
    "**Introduction**\n",
    "\n",
    "The task is to predict whether a passenger in an airport could be a Threat because he could have any kind of dangerous object ( gun, knifes ...). This objects could be detected by a millimetre wave scanner called the High Definition-Advanced Imaging Technology (HD-AIT) system.\n",
    "The scanner generates a complete set of body scanner images and we want to find any kind of anomalies in the image it could think us that the passenger could have an object and it could be a threat for the rest of passengers.\n",
    "We are going to apply clustering techniques for detection of anomalies in the image, and previously we are going to generate a complete training dataset with image that we are viewed before checking that the passenger don't have any kind of internal object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "5dcc3732-bef3-44a9-a9f7-c0031bdf493c",
    "_uuid": "49dcf09247abfef871c28bb767936b60baa3036f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import array, asarray, ma, zeros, sum\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from scipy.cluster.vq import vq, kmeans, whiten, kmeans2\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "1ddb84fa-49c6-4b2e-ab83-5b9fa9be0ac8",
    "_uuid": "4979653104b147671f429590b937b1c5309abd9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highresolution\n",
      "low-resolution\n",
      "modeldbscan\n",
      "modelstraining\n",
      "passenger-screening-algorithm-challenge\n",
      "\n",
      "Exception: Command '['ls', '../input/datainput']' returned non-zero exit status 2.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from subprocess import check_output\n",
    "try:\n",
    "    print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "    os.system('mkdir ./output')\n",
    "    os.system('mkdir ./output/Threats')\n",
    "    os.system('mkdir ./output/NoThreats')\n",
    "    os.system('mkdir ./training')\n",
    "    os.system('mkdir ./results')\n",
    "    os.system('mkdir ./models')\n",
    "    os.system('mkdir ./input')\n",
    "    print(check_output([\"ls\", \"../input/datainput\"]).decode(\"utf8\"))\n",
    "    print(check_output([\"ls\", \"../input/modelstraining\"]).decode(\"utf8\"))\n",
    "    print(check_output([\"ls\", \"../input/highresolution\"]).decode(\"utf8\"))\n",
    "    print(check_output([\"ls\", \"../input/modeldbscan\"]).decode(\"utf8\"))\n",
    "\n",
    "except Exception as exc:\n",
    "    print(\"Exception: {0}\".format(exc))\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2c294650-ce0c-492c-9234-3ae8b32237ff",
    "_uuid": "f8450046d92d639e21effdfaef01306108467310"
   },
   "source": [
    "**Analysis Approach**\n",
    "This original dataset contains a large number of body scans acquired by a new generation of millimetre wave scanner called the High Definition-Advanced Imaging Technology (HD-AIT) system. I considered the application of clustering techniques such as k-means and DBSCAN to generate a csv files with data that could be useful to do detect possible threats and marking the body zones scanned with possibles anomalies across the the careful analysis of distortion parameters in k-means techniques and the statistics parameters produced by  the application of DBSCAN techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "d6022323-bc15-48e9-bb3d-478ed1657801",
    "_uuid": "d4eac8087a5b06cd2fcf6a14cf9a6ef65544d93f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH_PHOTO_FILES = '.'\n",
    "NAME_FILE_MODEL_KMEANS = '../input/modelstraining/model_kmeans.csv'\n",
    "NAME_FILE_MODEL_DBSCAN = '../input/modeldbscan/model_dbscan.csv'\n",
    "DATA_FOR_PREDICTION_FILE = '../input/low-resolution/low_quality.csv'\n",
    "DATA_FOR_PREDICTION_FILE_FILTERED = '../input/highresolution/high_quality.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "cc483fe8-8fe8-46ab-a997-133808119ba2",
    "_uuid": "9b4ace7f17f9d1471b08539b68bc5a940cdefba1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############################################################################################################\n",
    "# Name: cluster_analisys\n",
    "# Autor: Ramiro Bueno Martínez\n",
    "# Date: 27/11/2017\n",
    "##########################################################################################################\n",
    "def cluster_analisys(subset):\n",
    "\ttry:\n",
    "\t\twhitened = whiten(subset)\n",
    "\t\tcodebook,distortion = kmeans(whitened,5)\n",
    "\t\treturn distortion,whitened,codebook\n",
    "\texcept Exception as exception:\n",
    "\t\tprint (\"cluster_analisys: Excepcion {0}\".format(exception))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "51e07080-d301-4b31-b9d4-2508eed14cdc",
    "_uuid": "d0a02a559c3c35137b4059c389822b080188136f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############################################################################################################\n",
    "# Name: creation_dataset_dbscan\n",
    "# Autor: Ramiro Bueno Martínez\n",
    "# Date: 30/11/2017\n",
    "# Description: The goal of fthis function is the dbscan analysis an generate a group of statistic datas\n",
    "# usuful in the building of a model training for finding possibles anomalies in the image \n",
    "############################################################################################################\n",
    "def creation_dataset_dbscan(dataset, FILENAME,highcontrast=False):\n",
    "\ttry:\n",
    "\t\toutput_dir = PATH_PHOTO_FILES + '/' + 'output'\n",
    "\t\tinput_dir = PATH_PHOTO_FILES + '/' + 'input'\n",
    "\t\tname_of_photo_file =  FILENAME\n",
    "\t\tprint(\"Starting creaction dataset dbscan {0}\".format(name_of_photo_file))\n",
    "\t\trange_images = [0,4,8,12]\n",
    "\t\tm_homegeneity = 0\n",
    "\t\tfor nth in range_images:\n",
    "\t\t\tan_img = get_single_image(name_of_photo_file, nth)  \t\t\t\t#returns the nth=3 image from the image stack\n",
    "\t\t\tif highcontrast == True:\n",
    "\t\t\t\timg_rescaled = convert_to_grayscale(an_img)\n",
    "\t\t\t\tan_img = spread_spectrum(img_rescaled)\n",
    "\t\t\tdata_array = np.array(an_img)\n",
    "\t\t\twhitened = whiten(data_array)\n",
    "\t\t\trecord = pd.DataFrame({'x_axes': whitened[:, 0],'y_axes':whitened[:, 1]})\n",
    "\t\t\tcenters = np.array(record)\n",
    "\t\t\tX, labels_true = make_blobs(n_samples=750, centers=centers, cluster_std=0.4, random_state=0)\n",
    "\t\t\tX = StandardScaler().fit_transform(X)\n",
    "\t\t\tdb = DBSCAN(eps=0.3, min_samples=10).fit(X)\n",
    "\t\t\tcore_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "\t\t\tcore_samples_mask[db.core_sample_indices_] = True\n",
    "\t\t\tlabels = db.labels_\n",
    "\t\t\tn_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "\t\t\tName = FILENAME\n",
    "\t\t\tnClusters = n_clusters_\n",
    "\t\t\tHomegeneity = metrics.homogeneity_score(labels_true, labels)\n",
    "\t\t\tm_homegeneity = m_homegeneity + Homegeneity\n",
    "\t\t\tCompleteness = \tmetrics.completeness_score(labels_true, labels)\n",
    "\t\t\tVmeasure = metrics.v_measure_score(labels_true, labels)\n",
    "\t\t\tARIndex = metrics.adjusted_rand_score(labels_true, labels)\n",
    "\t\t\tAMInformation = \tmetrics.adjusted_mutual_info_score(labels_true, labels)\n",
    "\t\t\tSilCoefficient = metrics.silhouette_score(X, labels)\n",
    "\t\t\tThreat = 'nothreat'\n",
    "\t\t\trecord_dbscan = pd.DataFrame([[Name, nClusters, Homegeneity, Completeness, Vmeasure, ARIndex, AMInformation, SilCoefficient, Threat]],columns=['Name','nClusters','Homegeneity','Completeness','Vmeasure','ARIndex','AMInformation','SilCoefficient','Threat'])\n",
    "\t\t\tdataset = dataset.append(record_dbscan,ignore_index=True)\n",
    "\t\t\t\n",
    "\t\tmedia = 0\n",
    "\t\tmedia = m_homegeneity / 4\n",
    "\t\tpercent = 5  # 5% of the mean value we suppose that its a wrong value \n",
    "\t\tthreshold_thread = media * percent / 100\n",
    "\t\tfor i in range(len(dataset)):\n",
    "\t\t\tif abs(media - dataset.loc[i,('Homegeneity')]) > threshold_thread: \n",
    "\t\t\t\tprint(\"Finded a possible case\")\n",
    "\t\t\t\tdataset.loc[i,('Threat')] = 'threat'\n",
    "\t\t\tif abs(media - dataset.loc[i,('Homegeneity')]) <= threshold_thread:\n",
    "\t\t\t\tdataset.loc[i,('Threat')] = 'nothreat'\n",
    "\texcept Exception as ex:\n",
    "\t\tprint(\"Exception: {0}\".format(ex))\n",
    "\t\tsys.exit(-1)\n",
    "\tfinally:\n",
    "\t\treturn dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "fb9a9aba-4a68-499e-96e7-7509b5ccffbd",
    "_uuid": "939e33644b539a34169d9a9c567ed82a18e0c753",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############################################################################################################\n",
    "# Name: creation_dataset_threats\n",
    "# Autor: Ramiro Bueno Martínez\n",
    "# Date: 27/11/2017\n",
    "# Description: The goal of this function is the finding of possible anomalies in the different kind of\n",
    "# images generated with the body scannes, using clustering techniques based in the analysis of different\n",
    "# part of the body and different possition imagees\n",
    "############################################################################################################\n",
    "def creation_dataset_threats(dataset, FILENAME, highcontrast=False):\n",
    "\t\tm_distortion = 0\n",
    "\t\tcol = 0\n",
    "\t\trow = 0\n",
    "\t\tnth = 0\n",
    "\t\toutput_dir = PATH_PHOTO_FILES + '/' + 'output'\n",
    "\t\tinput_dir = PATH_PHOTO_FILES + '/' + 'input'\n",
    "\t\tname_of_photo_file = FILENAME\n",
    "\t\tprint (\"Starting clustering Analisys: {0}\".format(FILENAME))\n",
    "\t\trange_images = [0,4,8,12]\n",
    "\t\ttry:\n",
    "\t\t\tfor nth in range_images:\n",
    "\t\t\t\tan_img = get_single_image(name_of_photo_file, nth)  \t\t\t\t#returns the nth=3 image from the image stack\n",
    "\t\t\t\tif highcontrast == True:\n",
    "\t\t\t\t\timg_rescaled = convert_to_grayscale(an_img)\n",
    "\t\t\t\t\tan_img = spread_spectrum(img_rescaled)\n",
    "\t\t\t\tdata_array = np.array(an_img)\n",
    "\t\t\t\tdistortion_array[nth,1],whitened,codebook= cluster_analisys(data_array)\n",
    "\t\t\t\tm_distortion = m_distortion + distortion_array[nth,1]\n",
    "\t\t\t\trecord = pd.DataFrame([[FILENAME, nth, distortion_array[nth,1],'nothreat']],columns=['Name','Nth','Distortion','Threat'])\n",
    "\t\t\t\tdataset = dataset.append(record,ignore_index=True)\n",
    "\t\t\t\tcol = col + 1\n",
    "\t\t\t\tif col % 4 == 0:\n",
    "\t\t\t\t\trow = row + 1\n",
    "\t\t\t\t\tcol = 0\n",
    "\t\t\t\tprint(\".\")\n",
    "\t\t\tmedia = 0\n",
    "\t\t\tmedia = m_distortion / 4\n",
    "\t\t\tpercent = 17  # 17% of the mean value we suppose that its a wrong value \n",
    "\t\t\tthreshold_thread = media * percent / 100\n",
    "\t\t\tfor i in range(len(dataset)):\n",
    "\t\t\t\tif abs(media - dataset.loc[i,('Distortion')]) > threshold_thread: \n",
    "\t\t\t\t\tdataset.loc[i,('Threat')] = 'threat'\n",
    "\t\t\t\tif abs(media - dataset.loc[i,('Distortion')]) <= threshold_thread:\n",
    "\t\t\t\t\tdataset.loc[i,('Threat')] = 'nothreat'\n",
    "\t\texcept Exception as exception:\n",
    "\t\t\tprint (\"Function [creation_dataset_threats]: Excepcion {0}\".format(exception))\n",
    "\t\t\tsys.exit(1)\n",
    "\t\tfinally:\n",
    "\t\t\treturn dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "ff3d8bf0-34f0-4900-a7ad-4e2f262735da",
    "_uuid": "cc11b623c77913c54873338c39b5608d678ac7d2",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############################################################################################################\n",
    "# Name: creation_dataset_threats\n",
    "# Autor: Ramiro Bueno Martínez\n",
    "# Date: 27/11/2017\n",
    "# Description: The goal of this function is the finding of possible anomalies in the different kind of\n",
    "# images generated with the body scannes, using clustering techniques based in the analysis of different\n",
    "# part of the body and different possition imagees\n",
    "############################################################################################################\n",
    "def creation_dataset_threats(dataset, FILENAME, highcontrast=False):\n",
    "\t\tm_distortion = 0\n",
    "\t\tcol = 0\n",
    "\t\trow = 0\n",
    "\t\tnth = 0\n",
    "\t\toutput_dir = PATH_PHOTO_FILES + '/' + 'output'\n",
    "\t\tinput_dir = PATH_PHOTO_FILES + '/' + 'input'\n",
    "\t\tname_of_photo_file = input_dir + '/' + FILENAME\n",
    "\t\tprint (\"Starting clustering Analisys: {0}\".format(FILENAME))\n",
    "\t\trange_images = [0,4,8,12]\n",
    "\t\ttry:\n",
    "\t\t\tfor nth in range_images:\n",
    "\t\t\t\tan_img = get_single_image(name_of_photo_file, nth)  \n",
    "\t\t\t\tif highcontrast == True:\n",
    "\t\t\t\t\timg_rescaled = convert_to_grayscale(an_img)\n",
    "\t\t\t\t\tan_img = spread_spectrum(img_rescaled)\n",
    "\t\t\t\tdata_array = np.array(an_img)\n",
    "\t\t\t\tdistortion_array[nth,1],whitened,codebook= cluster_analisys(data_array)\n",
    "\t\t\t\tm_distortion = m_distortion + distortion_array[nth,1]\n",
    "\t\t\t\trecord = pd.DataFrame([[FILENAME, nth, distortion_array[nth,1],'nothreat']],columns=['Name','Nth','Distortion','Threat'])\n",
    "\t\t\t\tdataset = dataset.append(record,ignore_index=True)\n",
    "\t\t\t\tcol = col + 1\n",
    "\t\t\t\tif col % 4 == 0:\n",
    "\t\t\t\t\trow = row + 1\n",
    "\t\t\t\t\tcol = 0\n",
    "\t\t\t\tprint(\".\")\n",
    "\t\t\tmedia = 0\n",
    "\t\t\tmedia = m_distortion / 4\n",
    "\t\t\tpercent = 17  # 17% of the mean value we suppose that its a wrong value \n",
    "\t\t\tthreshold_thread = media * percent / 100\n",
    "\t\t\tfor i in range(len(dataset)):\n",
    "\t\t\t\tif abs(media - dataset.loc[i,('Distortion')]) > threshold_thread: \n",
    "\t\t\t\t\tdataset.loc[i,('Threat')] = 'threat'\n",
    "\t\t\t\tif abs(media - dataset.loc[i,('Distortion')]) <= threshold_thread:\n",
    "\t\t\t\t\tdataset.loc[i,('Threat')] = 'nothreat'\n",
    "\t\texcept Exception as exception:\n",
    "\t\t\tprint (\"Function [creation_dataset_threats]: Excepcion {0}\".format(exception))\n",
    "\t\t\tsys.exit(1)\n",
    "\t\tfinally:\n",
    "\t\t\treturn dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "11fa2f6d-102f-47a1-9134-8f71b634b8a2",
    "_uuid": "7028fa94cf47b61a7a0b7c57520bd8793cc5a909",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################################################################################################\n",
    "# Name: print_screen_results\n",
    "# Autor: Ramiro Bueno Martínez\n",
    "# Date : 28/11/2017\n",
    "# Description: Function that plot the results obtained in 4 graphis\n",
    "# Graphic 1 - The body scan image of the people\n",
    "# Graphic 2 - Adaptative Histogram Equalization of the image\n",
    "# Graphic 3 - Graphic results after the image matrix of datas had been analysed with the k-means algorithm\n",
    "# Graphic 4 - Graphic results after the image matrix of datas had been analysed with the DBSCAN algorithm\n",
    "# Parameter: \n",
    "# Input: Image File\n",
    "# Output: \n",
    "#\tParameter1: Record k-means data analysis\n",
    "#\tParameter2: Record dbscan data analysis\n",
    "###########################################################################################################\n",
    "\n",
    "def print_screen_results(image):\n",
    "\tCOLORMAP = 'pink'\n",
    "\tfig, axarr = plt.subplots(nrows=2, ncols=2, figsize=(50, 25))\n",
    "\taxarr[0,0].set_title('Body Scanner Image')\n",
    "\taxarr[0,0].imshow(image, cmap=COLORMAP)\n",
    "\taxarr[0,1].set_title('Adaptive Histogram Equalization')\n",
    "\taxarr[0,1].hist(image.flatten(), bins=256, color='c')\n",
    "\tdata_array = np.array(image)\n",
    "\twhitened = whiten(data_array)\n",
    "\tcodebook,distortion = kmeans(whitened,5)\n",
    "\taxarr[1,0].scatter(whitened[:, 0], whitened[:, 1], c='b')\n",
    "\taxarr[1,0].scatter(codebook[:, 0], codebook[:, 1], c='r')\n",
    "\tstream = 'k-means analyis: Distortion {0}%'.format(distortion)\n",
    "\taxarr[1,0].set_title(stream)\n",
    "\trecord_kmeans = pd.DataFrame([[' ', 0, distortion,'nothreat']],columns=['Name','Nth','Distortion','Threat'])\n",
    "\twhitened = whiten(data_array)\n",
    "\trecord = pd.DataFrame({'x_axes': whitened[:, 0],'y_axes':whitened[:, 1]})\n",
    "\tcenters = np.array(record)\n",
    "\tX, labels_true = make_blobs(n_samples=750, centers=centers, cluster_std=0.4, random_state=0)\n",
    "\tX = StandardScaler().fit_transform(X)\n",
    "\tdb = DBSCAN(eps=0.3, min_samples=10).fit(X)\n",
    "\tcore_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "\tcore_samples_mask[db.core_sample_indices_] = True\n",
    "\tlabels = db.labels_\n",
    "\tn_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "\tplt.subplot(224)\n",
    "\tunique_labels = set(labels)\n",
    "\tcolors = [plt.cm.Spectral(each)\tfor each in np.linspace(0, 1, len(unique_labels))]\n",
    "\tfor k, col in zip(unique_labels, colors):\n",
    "\t\tif k == -1:\n",
    "\t\t\tcol = [0, 0, 0, 1]\n",
    "\t\tclass_member_mask = (labels == k)\n",
    "\t\txy = X[class_member_mask & core_samples_mask]\n",
    "\t\tplt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "\t\t\tmarkeredgecolor='k', markersize=14)\n",
    "\t\txy = X[class_member_mask & ~core_samples_mask]\n",
    "\t\tplt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "\t\t\tmarkeredgecolor='k', markersize=6)\n",
    "\t\tName = ''\n",
    "\t\tnClusters = n_clusters_\n",
    "\t\tHomegeneity = metrics.homogeneity_score(labels_true, labels)\n",
    "\t\tCompleteness = \tmetrics.completeness_score(labels_true, labels)\n",
    "\t\tVmeasure = metrics.v_measure_score(labels_true, labels)\n",
    "\t\tARIndex = metrics.adjusted_rand_score(labels_true, labels)\n",
    "\t\tAMInformation = \tmetrics.adjusted_mutual_info_score(labels_true, labels)\n",
    "\t\tSilCoefficient = metrics.silhouette_score(X, labels)\n",
    "\t\tThreat = 'nothreat'\n",
    "\t\trecord_dbscan = pd.DataFrame([[Name, nClusters, Homegeneity, Completeness, Vmeasure, ARIndex, AMInformation, SilCoefficient, Threat]],columns=['Name','nClusters','Homegeneity','Completeness','Vmeasure','ARIndex','AMInformation','SilCoefficient','Threat'])\n",
    "\tplt.show()\n",
    "\treturn record_kmeans, record_dbscan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "ecf9458b-5fa7-47b5-9c9e-ea92d7ccdf7f",
    "_uuid": "4d0de8b8f115bca17d281301d554ff64f0ce043e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_img(image,title='Image'):\n",
    "\t\n",
    "\tfig, axarr = plt.subplots(nrows=1, ncols=2, figsize=(20, 5))\n",
    "\taxarr[0].imshow(image, cmap='pink')\t\t\t#Put in the screen the image after adaptative histogram equialization\n",
    "\tplt.subplot(122)\n",
    "\tplt.hist(image.flatten(), bins=256, color='c')\n",
    "\tplt.title(title)\n",
    "\tplt.xlabel('Adaptive Histogram Equalization')\n",
    "\tplt.ylabel('Frequency')\n",
    "\tplt.show()\n",
    "\t\n",
    "\treturn image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bc58a94e-3bff-4cc7-8e1f-2ca75cb49a1e",
    "_uuid": "abcd9b1826a70c4dfc17173a9d9111bf093cf238"
   },
   "source": [
    "**Results SECTION 1: Prediction with svm algorithm**\n",
    "\n",
    "The first stage of our study is the generation of a complete training dataset with information about the possible threats detected in image. We are going to generate different kind of dataset (csv files) with distortion of the image parameters with respect to the mean of typical parameters obtained in images that we are checked that it hasn't presented any kind of threat using the next field parameters: \n",
    "\n",
    "      ['Name','Nth','Difference','Distortion', 'Mean', 'Threat']\n",
    " \n",
    "With the application of k-means algorithm we can obtain the distortion with respect to 5 cluster centroid in the measurement, this parameter it's analysed with respect to the sum of the mean value and an initial threshold, when the parameter it's out of this margins we are considered that we could have a possible anomaly that it's necessary to analyse deeply. \n",
    "\n",
    "To check the training dataset we are going to use a classification method (support vector machine) to do a prediction about of possibles anomalies in the image, and detect a threat in the passenger. \n",
    "\n",
    "This is a very simple approach with ncluster, 5 initial cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "4d228864-dabb-43dd-9c1e-2297e5d15614",
    "_uuid": "591e1a1258f7a1700a99059875ffd1f5f721fa3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_ANALISIS_TOOL: Initialization of the system...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/scipy/cluster/vq.py:141: RuntimeWarning: Some columns have standard deviation zero. The values of these columns will not change.\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passenger low-resolution it could suppose a thread at Body Scanner 3\n",
      "Image Distortion 67.31392277241774\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\tprint (\"DATA_ANALISIS_TOOL: Initialization of the system...\")\n",
    "\tdistortion_indicator1=0\n",
    "\ttry:\n",
    "\t\tdataset = pd.read_csv(NAME_FILE_MODEL_KMEANS, sep=',')\n",
    "\t\tn_samp = len(dataset)\n",
    "\t\tX, y = make_classification(n_samples=n_samp, n_features=4, random_state=0)\n",
    "\t\trow = 0\n",
    "\t\tfor index in range(len(dataset)):\n",
    "\t\t\tX[row][0]=dataset.loc[index,'Nth']\n",
    "\t\t\tX[row][1]=dataset.loc[index,'Distortion']\n",
    "\t\t\tX[row][2]=dataset.loc[index,'Difference']\n",
    "\t\t\tX[row][3]=dataset.loc[index,'Mean']\n",
    "\t\t\tif dataset.loc[index,'Threat'] == 'threat':\n",
    "\t\t\t\ty[index]=np.int32(1)\n",
    "\t\t\telse:\n",
    "\t\t\t\ty[index]=np.int32(0)\n",
    "\t\t\t\n",
    "\t\t\trow = row + 1\n",
    "\t\tclf = LinearSVC(random_state=0)\n",
    "\t\tclf.fit(X, y)\n",
    "\t\tdataset_new = pd.read_csv(DATA_FOR_PREDICTION_FILE, sep=',')\n",
    "\t\tdata_array = np.array(dataset_new)\n",
    "\t\tdistortion,whitened,codebook = cluster_analisys(data_array)\n",
    "\t\tmean_value = dataset['Distortion'].mean()\n",
    "\t\tdifference = abs(mean_value - distortion)\n",
    "\t\tdistortion_indicator1 = difference / mean_value * 100\n",
    "\t\tnth = 3\n",
    "\t\tresult_of_prediction = clf.predict([[nth,distortion,difference,mean_value]]) \t\n",
    "\t\tname_file = DATA_FOR_PREDICTION_FILE\n",
    "\t\tname_passenger = str(name_file).split('/')\n",
    "\t\tname_passenger = str(name_passenger[2]).split('.')\n",
    "\t\tname_passenger = name_passenger[0]\n",
    "\t\t\n",
    "\t\tif result_of_prediction == True:\n",
    "\t\t\tprint(\"Passenger {0} it could suppose a thread at Body Scanner {1}\".format(name_passenger,3))\n",
    "\t\t\tthreat_result = True\n",
    "\t\telse:\n",
    "\t\t\tprint(\"Passenger {0} it could suppose a thread at Body Scanner {1}\".format(namename_passenger,3))\n",
    "\texcept Exception as exception:\n",
    "\t\tprint (\"DATA_ANALISIS_TOOL: Excepcion {0}\".format(exception))\n",
    "\tfinally:\n",
    "\t\tprint(\"Image Distortion {0}\".format(distortion_indicator1))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "86f56207-514e-4a96-b1ed-12308801a9bd",
    "_uuid": "eb6bed4954de36f5367be4a14fbfbe6da5e2cb63"
   },
   "source": [
    "**Results SECTION 2: Prediction with svm algorithm over image with high contrast**\n",
    "\n",
    "In a second approach we are detect that any anomalies could be produced by images with less quality. At this point we are going to apply to cleaning the datainput initial, based in an increase of high quality image with a filtering of the image datainput (contrast filtering techniques)\n",
    "\n",
    "When we are tested the new results applying the same datainput and passed this input data across our support vector machine we can check in the output data that the results are better because we are reduced the distortion of the image and the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "6681d663-5eae-47be-b71a-03378efd5119",
    "_uuid": "656d24466b0910ee405f36d37e96a60f6e6b2557"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/scipy/cluster/vq.py:141: RuntimeWarning: Some columns have standard deviation zero. The values of these columns will not change.\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passenger highresolution it could suppose a thread at Body Scanner 3\n",
      "Image Distortion 5.737949315984402\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "\tname_file = DATA_FOR_PREDICTION_FILE_FILTERED\n",
    "\tdataset_new = pd.read_csv(DATA_FOR_PREDICTION_FILE_FILTERED, sep=',')\n",
    "\tdata_array = np.array(dataset_new)\n",
    "\tdistortion,whitened,codebook = cluster_analisys(data_array)\n",
    "\tmean_value = dataset['Distortion'].mean()\n",
    "\tdifference = abs(mean_value - distortion)\n",
    "\tdistortion_indicator2 = difference / mean_value * 100\n",
    "\tnth = 3\n",
    "\tresult_of_prediction = clf.predict([[nth,distortion,difference,mean_value]]) \t\n",
    "\tname_file = DATA_FOR_PREDICTION_FILE_FILTERED\n",
    "\tname_passenger = str(name_file).split('/')\n",
    "\tname_passenger = str(name_passenger[2]).split('.')\n",
    "\tname_passenger = name_passenger[0]\n",
    "\tif result_of_prediction == True:\n",
    "\t\tprint(\"Passenger {0} it could suppose a thread at Body Scanner {1}\".format(name_passenger,3))\n",
    "\t\tthreat_result = True\n",
    "\telse:\n",
    "\t\tprint(\"Passenger {0} it could suppose a thread at Body Scanner {1}\".format(name_passenger,3))\n",
    "\t\n",
    "\n",
    "except Exception as exception:\n",
    "\tprint (\"DATA_ANALISIS_TOOL: Excepcion {0}\".format(exception))\n",
    "finally:\n",
    "\tprint(\"Image Distortion {0}\".format(distortion_indicator2)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6a1c99c5-8c95-4e45-b220-8bd4ab4610b4",
    "_uuid": "b13273cbbeb8389225492beffbb23aa9c5cb7812"
   },
   "source": [
    "**Improvement in detection images with filtering** \n",
    "\n",
    "Also we are try to apply any techniques of DBSCAN for identify possibles case of anomalies in the image, but this tasks required more time and the purposes of this practice for me it's only the application of the knowledge acquired in the course, with a simple method of clustering to find mistakes and possible anomalies that it could think us that the passenger could have any kind of threat object. With a simple application of a method of classification for the prediction such as support vector machine I think we could achieve our initial goals joining the clustering analysis and support vector machine ( classification method) in a useful programme for detect possible threats of passengers in the control of the airports.   \n",
    "\n",
    "The improvement is found in the development of the practice with the application of image's cleaning techniques filtering obtaining a better difference results with respect the initial results around the mean value of image distortion, with an improvement in the distortion of image around of 0,61 reflected in the precession of the possible prediction.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "20e0deb5-34f0-44b5-bb47-bc110f370904",
    "_uuid": "76a7a004212d222de5377b9a147c3f3b56c03cb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image distortion improvement with the filtering image -61.57597345643334% \n"
     ]
    }
   ],
   "source": [
    "improvement = distortion_indicator2 - distortion_indicator1\n",
    "print(\"Image distortion improvement with the filtering image {0}% \".format(improvement))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
